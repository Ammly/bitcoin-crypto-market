{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114f55b7",
   "metadata": {},
   "source": [
    "# üöÄ Cryptocurrency Market Analysis: Phase 2-5\n",
    "## Data Loading, Understanding, Preprocessing & Historical Analysis\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Project Overview\n",
    "\n",
    "This analysis implements **Phase 2 through Phase 5** of our comprehensive cryptocurrency market analysis:\n",
    "\n",
    "- **Phase 2**: Data Loading & Understanding\n",
    "- **Phase 3**: Data Preprocessing & Feature Engineering  \n",
    "- **Phase 4**: Exploratory Data Analysis (EDA)\n",
    "- **Phase 5**: Historical Trend Analysis\n",
    "\n",
    "### üéØ Analysis Goals\n",
    "\n",
    "1. **Load & Validate Data**: Import multiple cryptocurrency datasets\n",
    "2. **Assess Data Quality**: Identify missing values and inconsistencies\n",
    "3. **Engineer Features**: Create derived metrics for analysis\n",
    "4. **Generate Statistics**: Comprehensive overview of market metrics\n",
    "5. **Analyze Trends**: Historical price evolution and market patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3f7f7",
   "metadata": {},
   "source": [
    "## üìö Import Required Libraries\n",
    "\n",
    "Setting up our analysis environment with essential data science libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111abee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Plotly for interactive visualizations\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ Pandas version: {pd.__version__}\")\n",
    "print(f\"üì¶ NumPy version: {np.__version__}\")\n",
    "print(f\"üì¶ Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"üì¶ Seaborn version: {sns.__version__}\")\n",
    "print(f\"üì¶ Analysis environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3de777",
   "metadata": {},
   "source": [
    "## üìÇ Initial Data Loading\n",
    "\n",
    "Let's start by exploring available cryptocurrency datasets and setting up our data loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory path\n",
    "DATA_DIR = 'd:\\\\Projects\\\\CoPilot\\\\Crypto\\\\bitcoin-crypto-market\\\\data\\\\raw'\n",
    "\n",
    "# Check if data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"‚ö†Ô∏è Data directory not found: {DATA_DIR}\")\n",
    "    print(\"Creating directory structure...\")\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    print(\"üìÅ Please place cryptocurrency CSV files in the data/raw directory\")\n",
    "else:\n",
    "    print(f\"‚úÖ Data directory found: {DATA_DIR}\")\n",
    "\n",
    "# Function to discover available cryptocurrency files\n",
    "def get_available_cryptos(data_dir):\n",
    "    \"\"\"Discover available cryptocurrency CSV files\"\"\"\n",
    "    csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "    crypto_names = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        filename = os.path.basename(file)\n",
    "        # Extract crypto name (assuming format: crypto_name.csv or coin_CryptoName.csv)\n",
    "        if filename.startswith('coin_'):\n",
    "            crypto_name = filename.replace('coin_', '').replace('.csv', '')\n",
    "        else:\n",
    "            crypto_name = filename.replace('.csv', '')\n",
    "        crypto_names.append(crypto_name)\n",
    "    \n",
    "    return sorted(crypto_names), csv_files\n",
    "\n",
    "# Function to load single cryptocurrency data\n",
    "def load_crypto_data(filepath, crypto_name):\n",
    "    \"\"\"Load and validate single cryptocurrency dataset\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Basic validation\n",
    "        if df.empty:\n",
    "            print(f\"‚ö†Ô∏è {crypto_name}: Empty dataset\")\n",
    "            return None\n",
    "        \n",
    "        # Add crypto identifier\n",
    "        df['Crypto'] = crypto_name\n",
    "        \n",
    "        # Convert Date column if exists\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.set_index('Date')\n",
    "        \n",
    "        print(f\"‚úÖ {crypto_name}: {len(df)} records loaded ({df.index.min().date()} to {df.index.max().date()})\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {crypto_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Discover available cryptocurrencies\n",
    "available_cryptos, csv_files = get_available_cryptos(DATA_DIR)\n",
    "\n",
    "print(f\"\\nüîç Data Discovery Results:\")\n",
    "print(f\"   ‚Ä¢ Available CSV files: {len(csv_files)}\")\n",
    "print(f\"   ‚Ä¢ Cryptocurrency datasets: {len(available_cryptos)}\")\n",
    "\n",
    "if available_cryptos:\n",
    "    print(f\"\\nüìã Available Cryptocurrencies:\")\n",
    "    for i, crypto in enumerate(available_cryptos, 1):\n",
    "        print(f\"   {i:2d}. {crypto}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No cryptocurrency CSV files found!\")\n",
    "    print(\"   Please ensure CSV files are placed in the data/raw directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b411fb0",
   "metadata": {},
   "source": [
    "## üîÑ Load Multiple Cryptocurrencies\n",
    "\n",
    "Now let's load the key cryptocurrencies we'll focus on for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60182875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key cryptocurrencies for analysis\n",
    "# Prioritize major cryptocurrencies by market cap and data availability\n",
    "KEY_CRYPTOS = [\n",
    "    'Bitcoin', 'Ethereum', 'BinanceCoin', 'XRP', 'Cardano',\n",
    "    'Solana', 'Dogecoin', 'Polkadot', 'Litecoin', 'ChainLink'\n",
    "]\n",
    "\n",
    "# Alternative names that might be in the dataset\n",
    "CRYPTO_ALIASES = {\n",
    "    'Bitcoin': ['bitcoin', 'BTC', 'btc'],\n",
    "    'Ethereum': ['ethereum', 'ETH', 'eth'],\n",
    "    'BinanceCoin': ['binancecoin', 'BNB', 'bnb', 'Binance'],\n",
    "    'XRP': ['xrp', 'ripple', 'Ripple'],\n",
    "    'Cardano': ['cardano', 'ADA', 'ada'],\n",
    "    'Solana': ['solana', 'SOL', 'sol'],\n",
    "    'Dogecoin': ['dogecoin', 'DOGE', 'doge'],\n",
    "    'Polkadot': ['polkadot', 'DOT', 'dot'],\n",
    "    'Litecoin': ['litecoin', 'LTC', 'ltc'],\n",
    "    'ChainLink': ['chainlink', 'LINK', 'link']\n",
    "}\n",
    "\n",
    "def find_crypto_file(crypto_name, available_cryptos, csv_files):\n",
    "    \"\"\"Find the correct file for a cryptocurrency considering aliases\"\"\"\n",
    "    # Direct match\n",
    "    if crypto_name in available_cryptos:\n",
    "        idx = available_cryptos.index(crypto_name)\n",
    "        return csv_files[idx]\n",
    "    \n",
    "    # Check aliases\n",
    "    if crypto_name in CRYPTO_ALIASES:\n",
    "        for alias in CRYPTO_ALIASES[crypto_name]:\n",
    "            if alias in available_cryptos:\n",
    "                idx = available_cryptos.index(alias)\n",
    "                return csv_files[idx]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Load cryptocurrency data\n",
    "crypto_data = {}\n",
    "loading_summary = []\n",
    "\n",
    "print(\"üìä Loading Key Cryptocurrencies...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for crypto_name in KEY_CRYPTOS:\n",
    "    filepath = find_crypto_file(crypto_name, available_cryptos, csv_files)\n",
    "    \n",
    "    if filepath:\n",
    "        df = load_crypto_data(filepath, crypto_name)\n",
    "        if df is not None:\n",
    "            crypto_data[crypto_name] = df\n",
    "            loading_summary.append({\n",
    "                'Cryptocurrency': crypto_name,\n",
    "                'Records': len(df),\n",
    "                'Start_Date': df.index.min(),\n",
    "                'End_Date': df.index.max(),\n",
    "                'Status': 'Loaded'\n",
    "            })\n",
    "        else:\n",
    "            loading_summary.append({\n",
    "                'Cryptocurrency': crypto_name,\n",
    "                'Records': 0,\n",
    "                'Start_Date': None,\n",
    "                'End_Date': None,\n",
    "                'Status': 'Failed'\n",
    "            })\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {crypto_name}: File not found\")\n",
    "        loading_summary.append({\n",
    "            'Cryptocurrency': crypto_name,\n",
    "            'Records': 0,\n",
    "            'Start_Date': None,\n",
    "            'End_Date': None,\n",
    "            'Status': 'Not Found'\n",
    "        })\n",
    "\n",
    "# Create loading summary DataFrame\n",
    "loading_df = pd.DataFrame(loading_summary)\n",
    "\n",
    "print(f\"\\nüìà Loading Summary:\")\n",
    "print(f\"   ‚Ä¢ Successfully loaded: {len(crypto_data)} cryptocurrencies\")\n",
    "print(f\"   ‚Ä¢ Failed to load: {len(KEY_CRYPTOS) - len(crypto_data)} cryptocurrencies\")\n",
    "\n",
    "# Display detailed summary\n",
    "display(loading_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426ce3a",
   "metadata": {},
   "source": [
    "## üîç Data Quality Assessment\n",
    "\n",
    "Let's thoroughly examine the quality of our loaded cryptocurrency datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13fc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data quality assessment\n",
    "def assess_data_quality(crypto_data):\n",
    "    \"\"\"Perform comprehensive data quality assessment\"\"\"\n",
    "    quality_report = []\n",
    "    \n",
    "    print(\"üîç Data Quality Assessment\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in crypto_data.items():\n",
    "        print(f\"\\nüìä {name} Data Quality:\")\n",
    "        \n",
    "        # Basic info\n",
    "        total_records = len(df)\n",
    "        date_range = (df.index.max() - df.index.min()).days\n",
    "        \n",
    "        # Missing values analysis\n",
    "        missing_values = df.isnull().sum()\n",
    "        total_missing = missing_values.sum()\n",
    "        missing_percentage = (total_missing / (len(df) * len(df.columns))) * 100\n",
    "        \n",
    "        # Data type analysis\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        # Price consistency checks\n",
    "        price_issues = 0\n",
    "        if all(col in df.columns for col in ['High', 'Low', 'Open', 'Close']):\n",
    "            # Check if High >= Low\n",
    "            high_low_issues = (df['High'] < df['Low']).sum()\n",
    "            # Check if High >= Open and High >= Close\n",
    "            high_open_issues = (df['High'] < df['Open']).sum()\n",
    "            high_close_issues = (df['High'] < df['Close']).sum()\n",
    "            # Check if Low <= Open and Low <= Close\n",
    "            low_open_issues = (df['Low'] > df['Open']).sum()\n",
    "            low_close_issues = (df['Low'] > df['Close']).sum()\n",
    "            \n",
    "            price_issues = high_low_issues + high_open_issues + high_close_issues + low_open_issues + low_close_issues\n",
    "        \n",
    "        # Duplicate dates\n",
    "        duplicate_dates = df.index.duplicated().sum()\n",
    "        \n",
    "        # Zero or negative values in price columns\n",
    "        negative_values = 0\n",
    "        zero_values = 0\n",
    "        price_cols = ['Open', 'High', 'Low', 'Close']\n",
    "        for col in price_cols:\n",
    "            if col in df.columns:\n",
    "                negative_values += (df[col] < 0).sum()\n",
    "                zero_values += (df[col] == 0).sum()\n",
    "        \n",
    "        # Calculate data completeness\n",
    "        completeness = ((len(df) * len(df.columns) - total_missing) / (len(df) * len(df.columns))) * 100\n",
    "        \n",
    "        # Store quality metrics\n",
    "        quality_metrics = {\n",
    "            'Cryptocurrency': name,\n",
    "            'Total_Records': total_records,\n",
    "            'Date_Range_Days': date_range,\n",
    "            'Missing_Values': total_missing,\n",
    "            'Missing_Percentage': missing_percentage,\n",
    "            'Price_Logic_Issues': price_issues,\n",
    "            'Duplicate_Dates': duplicate_dates,\n",
    "            'Negative_Values': negative_values,\n",
    "            'Zero_Values': zero_values,\n",
    "            'Data_Completeness': completeness,\n",
    "            'Numeric_Columns': len(numeric_cols)\n",
    "        }\n",
    "        quality_report.append(quality_metrics)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"   ‚Ä¢ Records: {total_records:,}\")\n",
    "        print(f\"   ‚Ä¢ Date range: {date_range} days\")\n",
    "        print(f\"   ‚Ä¢ Missing values: {total_missing} ({missing_percentage:.2f}%)\")\n",
    "        print(f\"   ‚Ä¢ Data completeness: {completeness:.2f}%\")\n",
    "        print(f\"   ‚Ä¢ Price logic issues: {price_issues}\")\n",
    "        print(f\"   ‚Ä¢ Duplicate dates: {duplicate_dates}\")\n",
    "        print(f\"   ‚Ä¢ Negative/Zero values: {negative_values}/{zero_values}\")\n",
    "        \n",
    "        # Show missing values by column if any\n",
    "        if total_missing > 0:\n",
    "            print(f\"   ‚Ä¢ Missing by column:\")\n",
    "            for col, count in missing_values[missing_values > 0].items():\n",
    "                pct = (count / len(df)) * 100\n",
    "                print(f\"     - {col}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    return pd.DataFrame(quality_report)\n",
    "\n",
    "# Perform quality assessment\n",
    "quality_df = assess_data_quality(crypto_data)\n",
    "\n",
    "print(f\"\\nüìã Quality Assessment Summary:\")\n",
    "display(quality_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b73e2",
   "metadata": {},
   "source": [
    "## üìä Data Structure Exploration\n",
    "\n",
    "Let's examine the detailed structure of our cryptocurrency datasets, using Bitcoin as our reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addbd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed data structure exploration\n",
    "def explore_data_structure(crypto_data):\n",
    "    \"\"\"Explore detailed structure of cryptocurrency datasets\"\"\"\n",
    "    \n",
    "    # Use Bitcoin as primary reference (most complete dataset typically)\n",
    "    reference_crypto = None\n",
    "    for crypto in ['Bitcoin', 'bitcoin', 'BTC', 'btc']:\n",
    "        if crypto in crypto_data:\n",
    "            reference_crypto = crypto\n",
    "            break\n",
    "    \n",
    "    if not reference_crypto:\n",
    "        reference_crypto = list(crypto_data.keys())[0]\n",
    "    \n",
    "    ref_df = crypto_data[reference_crypto]\n",
    "    \n",
    "    print(f\"üîç Detailed Structure Analysis - Reference: {reference_crypto}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic structure\n",
    "    print(f\"\\nüìä Dataset Dimensions:\")\n",
    "    print(f\"   ‚Ä¢ Shape: {ref_df.shape}\")\n",
    "    print(f\"   ‚Ä¢ Rows: {ref_df.shape[0]:,}\")\n",
    "    print(f\"   ‚Ä¢ Columns: {ref_df.shape[1]}\")\n",
    "    \n",
    "    # Column information\n",
    "    print(f\"\\nüìã Column Information:\")\n",
    "    print(f\"   ‚Ä¢ Column Names: {list(ref_df.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Data Types:\")\n",
    "    for col, dtype in ref_df.dtypes.items():\n",
    "        print(f\"     - {col}: {dtype}\")\n",
    "    \n",
    "    # Date range information\n",
    "    print(f\"\\nüìÖ Date Range:\")\n",
    "    print(f\"   ‚Ä¢ Start Date: {ref_df.index.min().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"   ‚Ä¢ End Date: {ref_df.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"   ‚Ä¢ Total Days: {(ref_df.index.max() - ref_df.index.min()).days:,}\")\n",
    "    print(f\"   ‚Ä¢ Index Type: {type(ref_df.index)}\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(f\"\\nüìà Sample Data - First 5 Rows:\")\n",
    "    display(ref_df.head())\n",
    "    \n",
    "    print(f\"\\nüìâ Sample Data - Last 5 Rows:\")\n",
    "    display(ref_df.tail())\n",
    "    \n",
    "    # Basic statistics for numeric columns\n",
    "    print(f\"\\nüìä Basic Statistics:\")\n",
    "    numeric_cols = ref_df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        display(ref_df[numeric_cols].describe())\n",
    "    \n",
    "    # Check for expected cryptocurrency columns\n",
    "    expected_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Market Cap']\n",
    "    missing_cols = [col for col in expected_cols if col not in ref_df.columns]\n",
    "    present_cols = [col for col in expected_cols if col in ref_df.columns]\n",
    "    \n",
    "    print(f\"\\nüîó Standard Cryptocurrency Columns:\")\n",
    "    print(f\"   ‚Ä¢ Present: {present_cols}\")\n",
    "    if missing_cols:\n",
    "        print(f\"   ‚Ä¢ Missing: {missing_cols}\")\n",
    "    \n",
    "    return ref_df\n",
    "\n",
    "# Explore structure\n",
    "reference_df = explore_data_structure(crypto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97feca7",
   "metadata": {},
   "source": [
    "## üîç Missing Values Analysis\n",
    "\n",
    "Let's conduct a comprehensive analysis of missing values across all cryptocurrencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive missing values analysis\n",
    "def analyze_missing_values(crypto_data):\n",
    "    \"\"\"Detailed missing values analysis across all cryptocurrencies\"\"\"\n",
    "    \n",
    "    print(\"üîç Comprehensive Missing Values Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Overall missing values summary\n",
    "    missing_summary = []\n",
    "    \n",
    "    for name, df in crypto_data.items():\n",
    "        total_cells = len(df) * len(df.columns)\n",
    "        missing_cells = df.isnull().sum().sum()\n",
    "        missing_percentage = (missing_cells / total_cells) * 100\n",
    "        \n",
    "        missing_summary.append({\n",
    "            'Cryptocurrency': name,\n",
    "            'Total_Cells': total_cells,\n",
    "            'Missing_Cells': missing_cells,\n",
    "            'Missing_Percentage': missing_percentage,\n",
    "            'Complete_Rows': len(df.dropna()),\n",
    "            'Incomplete_Rows': len(df) - len(df.dropna())\n",
    "        })\n",
    "    \n",
    "    missing_df = pd.DataFrame(missing_summary)\n",
    "    missing_df = missing_df.sort_values('Missing_Percentage', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüìä Missing Values Summary by Cryptocurrency:\")\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Detailed missing values by column\n",
    "    print(f\"\\nüìã Missing Values by Column:\")\n",
    "    \n",
    "    all_columns = set()\n",
    "    for df in crypto_data.values():\n",
    "        all_columns.update(df.columns)\n",
    "    \n",
    "    column_missing = []\n",
    "    for col in sorted(all_columns):\n",
    "        col_data = []\n",
    "        for name, df in crypto_data.items():\n",
    "            if col in df.columns:\n",
    "                missing_count = df[col].isnull().sum()\n",
    "                missing_pct = (missing_count / len(df)) * 100\n",
    "                col_data.append({\n",
    "                    'Cryptocurrency': name,\n",
    "                    'Column': col,\n",
    "                    'Missing_Count': missing_count,\n",
    "                    'Missing_Percentage': missing_pct\n",
    "                })\n",
    "        \n",
    "        if col_data:\n",
    "            col_df = pd.DataFrame(col_data)\n",
    "            if col_df['Missing_Count'].sum() > 0:  # Only show columns with missing values\n",
    "                print(f\"\\n   üî∏ {col}:\")\n",
    "                for _, row in col_df[col_df['Missing_Count'] > 0].iterrows():\n",
    "                    print(f\"     - {row['Cryptocurrency']}: {row['Missing_Count']} ({row['Missing_Percentage']:.1f}%)\")\n",
    "    \n",
    "    # Missing value patterns\n",
    "    print(f\"\\nüîç Missing Value Patterns:\")\n",
    "    \n",
    "    for name, df in crypto_data.items():\n",
    "        if df.isnull().sum().sum() > 0:\n",
    "            print(f\"\\n   üìä {name}:\")\n",
    "            \n",
    "            # Check for consecutive missing values\n",
    "            for col in df.columns:\n",
    "                if df[col].isnull().sum() > 0:\n",
    "                    # Find consecutive missing value sequences\n",
    "                    is_missing = df[col].isnull()\n",
    "                    missing_groups = is_missing.ne(is_missing.shift()).cumsum()\n",
    "                    consecutive_missing = is_missing.groupby(missing_groups).sum()\n",
    "                    max_consecutive = consecutive_missing.max()\n",
    "                    \n",
    "                    print(f\"     - {col}: Max consecutive missing = {max_consecutive}\")\n",
    "    \n",
    "    # Data quality recommendations\n",
    "    print(f\"\\nüí° Data Quality Recommendations:\")\n",
    "    \n",
    "    high_missing = missing_df[missing_df['Missing_Percentage'] > 10]\n",
    "    if not high_missing.empty:\n",
    "        print(f\"   ‚ö†Ô∏è High missing data (>10%):\")\n",
    "        for _, row in high_missing.iterrows():\n",
    "            print(f\"     - {row['Cryptocurrency']}: {row['Missing_Percentage']:.1f}% missing\")\n",
    "        print(f\"   üí° Consider excluding or applying advanced imputation\")\n",
    "    \n",
    "    moderate_missing = missing_df[(missing_df['Missing_Percentage'] > 1) & (missing_df['Missing_Percentage'] <= 10)]\n",
    "    if not moderate_missing.empty:\n",
    "        print(f\"   üü° Moderate missing data (1-10%):\")\n",
    "        for _, row in moderate_missing.iterrows():\n",
    "            print(f\"     - {row['Cryptocurrency']}: {row['Missing_Percentage']:.1f}% missing\")\n",
    "        print(f\"   üí° Apply forward fill or interpolation\")\n",
    "    \n",
    "    clean_data = missing_df[missing_df['Missing_Percentage'] <= 1]\n",
    "    if not clean_data.empty:\n",
    "        print(f\"   ‚úÖ Clean data (‚â§1% missing):\")\n",
    "        for _, row in clean_data.iterrows():\n",
    "            print(f\"     - {row['Cryptocurrency']}: {row['Missing_Percentage']:.1f}% missing\")\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "# Perform missing values analysis\n",
    "missing_analysis = analyze_missing_values(crypto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ac5cc",
   "metadata": {},
   "source": [
    "## üßπ Data Preprocessing & Feature Engineering\n",
    "\n",
    "Now let's clean our data and engineer features for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and feature engineering\n",
    "def preprocess_crypto_data(df, crypto_name):\n",
    "    \"\"\"Preprocess individual cryptocurrency data\"\"\"\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # 1. Handle missing values\n",
    "    # Forward fill for small gaps (‚â§ 3 days)\n",
    "    df_processed = df_processed.fillna(method='ffill', limit=3)\n",
    "    \n",
    "    # Interpolate remaining missing values for numeric columns\n",
    "    numeric_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        df_processed[col] = df_processed[col].interpolate(method='linear')\n",
    "    \n",
    "    # 2. Remove duplicates (keep first occurrence)\n",
    "    df_processed = df_processed[~df_processed.index.duplicated(keep='first')]\n",
    "    \n",
    "    # 3. Sort by date\n",
    "    df_processed = df_processed.sort_index()\n",
    "    \n",
    "    # 4. Feature Engineering - Price Features\n",
    "    if 'Close' in df_processed.columns:\n",
    "        # Daily returns\n",
    "        df_processed['Daily_Return'] = df_processed['Close'].pct_change()\n",
    "        \n",
    "        # Log returns (better for analysis)\n",
    "        df_processed['Log_Return'] = np.log(df_processed['Close'] / df_processed['Close'].shift(1))\n",
    "        \n",
    "        # Price change (absolute)\n",
    "        if 'Open' in df_processed.columns:\n",
    "            df_processed['Price_Change'] = df_processed['Close'] - df_processed['Open']\n",
    "            df_processed['Price_Change_Pct'] = (df_processed['Close'] - df_processed['Open']) / df_processed['Open']\n",
    "    \n",
    "    # Price range features\n",
    "    if all(col in df_processed.columns for col in ['High', 'Low', 'Open']):\n",
    "        df_processed['Price_Range'] = df_processed['High'] - df_processed['Low']\n",
    "        df_processed['Range_Pct'] = (df_processed['High'] - df_processed['Low']) / df_processed['Open'] * 100\n",
    "    \n",
    "    # 5. Moving Averages\n",
    "    if 'Close' in df_processed.columns:\n",
    "        df_processed['MA7'] = df_processed['Close'].rolling(window=7, min_periods=1).mean()\n",
    "        df_processed['MA30'] = df_processed['Close'].rolling(window=30, min_periods=1).mean()\n",
    "        df_processed['MA90'] = df_processed['Close'].rolling(window=90, min_periods=1).mean()\n",
    "        df_processed['MA200'] = df_processed['Close'].rolling(window=200, min_periods=1).mean()\n",
    "    \n",
    "    # 6. Volatility Features\n",
    "    if 'Daily_Return' in df_processed.columns:\n",
    "        df_processed['Volatility_7'] = df_processed['Daily_Return'].rolling(window=7, min_periods=1).std()\n",
    "        df_processed['Volatility_30'] = df_processed['Daily_Return'].rolling(window=30, min_periods=1).std()\n",
    "        df_processed['Volatility_90'] = df_processed['Daily_Return'].rolling(window=90, min_periods=1).std()\n",
    "    \n",
    "    # 7. Cumulative Returns\n",
    "    if 'Daily_Return' in df_processed.columns:\n",
    "        df_processed['Cumulative_Return'] = (1 + df_processed['Daily_Return']).cumprod()\n",
    "    \n",
    "    # 8. Volume Features\n",
    "    if 'Volume' in df_processed.columns:\n",
    "        df_processed['Volume_Change'] = df_processed['Volume'].pct_change()\n",
    "        df_processed['Volume_MA30'] = df_processed['Volume'].rolling(window=30, min_periods=1).mean()\n",
    "        df_processed['Volume_Ratio'] = df_processed['Volume'] / df_processed['Volume_MA30']\n",
    "    \n",
    "    # 9. Date-based Features\n",
    "    df_processed['Year'] = df_processed.index.year\n",
    "    df_processed['Month'] = df_processed.index.month\n",
    "    df_processed['DayOfWeek'] = df_processed.index.dayofweek\n",
    "    df_processed['Quarter'] = df_processed.index.quarter\n",
    "    df_processed['DayOfYear'] = df_processed.index.dayofyear\n",
    "    \n",
    "    # 10. Technical Indicators\n",
    "    if 'Close' in df_processed.columns:\n",
    "        # RSI (Relative Strength Index) - simplified version\n",
    "        delta = df_processed['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()\n",
    "        rs = gain / loss\n",
    "        df_processed['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    print(f\"‚úÖ {crypto_name}: Preprocessing complete - {len(df_processed)} records, {len(df_processed.columns)} features\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Process all cryptocurrency data\n",
    "processed_crypto_data = {}\n",
    "feature_summary = []\n",
    "\n",
    "print(\"üßπ Data Preprocessing & Feature Engineering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, df in crypto_data.items():\n",
    "    processed_df = preprocess_crypto_data(df, name)\n",
    "    processed_crypto_data[name] = processed_df\n",
    "    \n",
    "    # Track feature engineering results\n",
    "    original_features = len(crypto_data[name].columns)\n",
    "    new_features = len(processed_df.columns)\n",
    "    added_features = new_features - original_features\n",
    "    \n",
    "    feature_summary.append({\n",
    "        'Cryptocurrency': name,\n",
    "        'Original_Features': original_features,\n",
    "        'New_Features': new_features,\n",
    "        'Added_Features': added_features,\n",
    "        'Records_After_Processing': len(processed_df)\n",
    "    })\n",
    "\n",
    "# Display feature engineering summary\n",
    "feature_df = pd.DataFrame(feature_summary)\n",
    "print(f\"\\nüìä Feature Engineering Summary:\")\n",
    "display(feature_df)\n",
    "\n",
    "# Show example of new features for Bitcoin\n",
    "if 'Bitcoin' in processed_crypto_data:\n",
    "    btc_processed = processed_crypto_data['Bitcoin']\n",
    "    print(f\"\\nüîç Example: New Features for Bitcoin\")\n",
    "    \n",
    "    # Show original vs new columns\n",
    "    original_cols = crypto_data['Bitcoin'].columns.tolist()\n",
    "    new_cols = [col for col in btc_processed.columns if col not in original_cols]\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Original columns: {len(original_cols)}\")\n",
    "    print(f\"   ‚Ä¢ New columns added: {len(new_cols)}\")\n",
    "    print(f\"   ‚Ä¢ New features: {new_cols}\")\n",
    "    \n",
    "    # Show sample of key features\n",
    "    sample_features = ['Close', 'Daily_Return', 'MA30', 'Volatility_30', 'RSI']\n",
    "    available_features = [col for col in sample_features if col in btc_processed.columns]\n",
    "    \n",
    "    print(f\"\\nüìà Sample Feature Values (Last 5 Days):\")\n",
    "    display(btc_processed[available_features].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a0159",
   "metadata": {},
   "source": [
    "## üìä Summary Statistics & Overview\n",
    "\n",
    "Let's generate comprehensive summary statistics for all cryptocurrencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary statistics\n",
    "def calculate_comprehensive_stats(crypto_data):\n",
    "    \"\"\"Calculate comprehensive statistics for all cryptocurrencies\"\"\"\n",
    "    \n",
    "    summary_stats = []\n",
    "    \n",
    "    print(\"üìä Calculating Comprehensive Statistics\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in crypto_data.items():\n",
    "        stats_dict = {'Cryptocurrency': name}\n",
    "        \n",
    "        # Basic info\n",
    "        stats_dict['Total_Records'] = len(df)\n",
    "        stats_dict['Date_Range_Days'] = (df.index.max() - df.index.min()).days\n",
    "        stats_dict['Start_Date'] = df.index.min()\n",
    "        stats_dict['End_Date'] = df.index.max()\n",
    "        \n",
    "        # Price statistics\n",
    "        if 'Close' in df.columns:\n",
    "            stats_dict['Current_Price'] = df['Close'].iloc[-1]\n",
    "            stats_dict['Min_Price'] = df['Close'].min()\n",
    "            stats_dict['Max_Price'] = df['Close'].max()\n",
    "            stats_dict['Avg_Price'] = df['Close'].mean()\n",
    "            stats_dict['Median_Price'] = df['Close'].median()\n",
    "            stats_dict['Price_Std'] = df['Close'].std()\n",
    "            \n",
    "            # Calculate total return\n",
    "            first_price = df['Close'].dropna().iloc[0]\n",
    "            last_price = df['Close'].dropna().iloc[-1]\n",
    "            stats_dict['Total_Return_Pct'] = ((last_price - first_price) / first_price) * 100\n",
    "        \n",
    "        # Return statistics\n",
    "        if 'Daily_Return' in df.columns:\n",
    "            returns = df['Daily_Return'].dropna()\n",
    "            stats_dict['Avg_Daily_Return'] = returns.mean()\n",
    "            stats_dict['Median_Daily_Return'] = returns.median()\n",
    "            stats_dict['Daily_Volatility'] = returns.std()\n",
    "            stats_dict['Annualized_Volatility'] = returns.std() * np.sqrt(252)\n",
    "            stats_dict['Skewness'] = returns.skew()\n",
    "            stats_dict['Kurtosis'] = returns.kurtosis()\n",
    "            stats_dict['Min_Daily_Return'] = returns.min()\n",
    "            stats_dict['Max_Daily_Return'] = returns.max()\n",
    "        \n",
    "        # Volume statistics\n",
    "        if 'Volume' in df.columns:\n",
    "            volume_data = df['Volume'].dropna()\n",
    "            stats_dict['Avg_Volume'] = volume_data.mean()\n",
    "            stats_dict['Median_Volume'] = volume_data.median()\n",
    "            stats_dict['Max_Volume'] = volume_data.max()\n",
    "            stats_dict['Volume_Std'] = volume_data.std()\n",
    "        \n",
    "        # Market Cap statistics\n",
    "        if 'Market Cap' in df.columns:\n",
    "            mcap_data = df['Market Cap'].dropna()\n",
    "            if len(mcap_data) > 0:\n",
    "                stats_dict['Current_Market_Cap'] = mcap_data.iloc[-1]\n",
    "                stats_dict['Avg_Market_Cap'] = mcap_data.mean()\n",
    "                stats_dict['Max_Market_Cap'] = mcap_data.max()\n",
    "        \n",
    "        # Risk metrics\n",
    "        if 'Daily_Return' in df.columns and 'Close' in df.columns:\n",
    "            # Calculate maximum drawdown\n",
    "            cumulative = (1 + df['Daily_Return'].fillna(0)).cumprod()\n",
    "            running_max = cumulative.expanding().max()\n",
    "            drawdown = (cumulative - running_max) / running_max\n",
    "            stats_dict['Max_Drawdown'] = drawdown.min()\n",
    "            \n",
    "            # Sharpe ratio (assuming 0% risk-free rate)\n",
    "            if stats_dict['Daily_Volatility'] > 0:\n",
    "                stats_dict['Sharpe_Ratio'] = stats_dict['Avg_Daily_Return'] / stats_dict['Daily_Volatility'] * np.sqrt(252)\n",
    "        \n",
    "        summary_stats.append(stats_dict)\n",
    "        \n",
    "        print(f\"‚úÖ {name}: Statistics calculated\")\n",
    "    \n",
    "    return pd.DataFrame(summary_stats)\n",
    "\n",
    "# Calculate comprehensive statistics\n",
    "comprehensive_stats = calculate_comprehensive_stats(processed_crypto_data)\n",
    "\n",
    "# Display key metrics\n",
    "print(f\"\\nüìà Key Performance Metrics:\")\n",
    "key_metrics = ['Cryptocurrency', 'Current_Price', 'Total_Return_Pct', 'Annualized_Volatility', 'Sharpe_Ratio', 'Max_Drawdown']\n",
    "available_key_metrics = [col for col in key_metrics if col in comprehensive_stats.columns]\n",
    "display(comprehensive_stats[available_key_metrics].round(2))\n",
    "\n",
    "# Display price statistics\n",
    "print(f\"\\nüí∞ Price Statistics:\")\n",
    "price_metrics = ['Cryptocurrency', 'Min_Price', 'Max_Price', 'Avg_Price', 'Current_Price']\n",
    "available_price_metrics = [col for col in price_metrics if col in comprehensive_stats.columns]\n",
    "display(comprehensive_stats[available_price_metrics].round(2))\n",
    "\n",
    "# Display return statistics\n",
    "print(f\"\\nüìä Return & Risk Statistics:\")\n",
    "return_metrics = ['Cryptocurrency', 'Avg_Daily_Return', 'Daily_Volatility', 'Min_Daily_Return', 'Max_Daily_Return']\n",
    "available_return_metrics = [col for col in return_metrics if col in comprehensive_stats.columns]\n",
    "display(comprehensive_stats[available_return_metrics].round(4))\n",
    "\n",
    "# Identify top performers\n",
    "if 'Total_Return_Pct' in comprehensive_stats.columns:\n",
    "    best_performer = comprehensive_stats.loc[comprehensive_stats['Total_Return_Pct'].idxmax()]\n",
    "    worst_performer = comprehensive_stats.loc[comprehensive_stats['Total_Return_Pct'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nüèÜ Performance Highlights:\")\n",
    "    print(f\"   ‚Ä¢ Best Performer: {best_performer['Cryptocurrency']} ({best_performer['Total_Return_Pct']:.1f}% total return)\")\n",
    "    print(f\"   ‚Ä¢ Worst Performer: {worst_performer['Cryptocurrency']} ({worst_performer['Total_Return_Pct']:.1f}% total return)\")\n",
    "\n",
    "# Identify risk characteristics\n",
    "if 'Annualized_Volatility' in comprehensive_stats.columns:\n",
    "    most_volatile = comprehensive_stats.loc[comprehensive_stats['Annualized_Volatility'].idxmax()]\n",
    "    least_volatile = comprehensive_stats.loc[comprehensive_stats['Annualized_Volatility'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nüìä Risk Characteristics:\")\n",
    "    print(f\"   ‚Ä¢ Most Volatile: {most_volatile['Cryptocurrency']} ({most_volatile['Annualized_Volatility']:.1%} annual volatility)\")\n",
    "    print(f\"   ‚Ä¢ Least Volatile: {least_volatile['Cryptocurrency']} ({least_volatile['Annualized_Volatility']:.1%} annual volatility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb177111",
   "metadata": {},
   "source": [
    "## üìà Historical Trend Analysis\n",
    "\n",
    "Let's analyze the historical price evolution and market trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical trend analysis - Bitcoin focus\n",
    "def analyze_bitcoin_trends(bitcoin_df):\n",
    "    \"\"\"Comprehensive Bitcoin historical analysis\"\"\"\n",
    "    \n",
    "    print(\"üìà Bitcoin Historical Trend Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic trend statistics\n",
    "    start_price = bitcoin_df['Close'].iloc[0]\n",
    "    end_price = bitcoin_df['Close'].iloc[-1]\n",
    "    total_return = ((end_price - start_price) / start_price) * 100\n",
    "    \n",
    "    print(f\"üìä Bitcoin Price Evolution:\")\n",
    "    print(f\"   ‚Ä¢ Start Price: ${start_price:,.2f}\")\n",
    "    print(f\"   ‚Ä¢ End Price: ${end_price:,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Total Return: {total_return:,.1f}%\")\n",
    "    print(f\"   ‚Ä¢ CAGR: {((end_price/start_price)**(1/(len(bitcoin_df)/365.25))-1)*100:.1f}%\")\n",
    "    \n",
    "    # Year-over-year analysis\n",
    "    bitcoin_df['Year'] = bitcoin_df.index.year\n",
    "    yearly_stats = []\n",
    "    \n",
    "    for year in sorted(bitcoin_df['Year'].unique()):\n",
    "        year_data = bitcoin_df[bitcoin_df['Year'] == year]\n",
    "        if len(year_data) > 1:\n",
    "            year_start = year_data['Close'].iloc[0]\n",
    "            year_end = year_data['Close'].iloc[-1]\n",
    "            year_return = ((year_end - year_start) / year_start) * 100\n",
    "            year_volatility = year_data['Daily_Return'].std() * np.sqrt(252) * 100\n",
    "            year_high = year_data['High'].max()\n",
    "            year_low = year_data['Low'].min()\n",
    "            \n",
    "            yearly_stats.append({\n",
    "                'Year': year,\n",
    "                'Start_Price': year_start,\n",
    "                'End_Price': year_end,\n",
    "                'Year_Return_Pct': year_return,\n",
    "                'Annual_Volatility_Pct': year_volatility,\n",
    "                'Year_High': year_high,\n",
    "                'Year_Low': year_low,\n",
    "                'Days_Traded': len(year_data)\n",
    "            })\n",
    "    \n",
    "    yearly_df = pd.DataFrame(yearly_stats)\n",
    "    print(f\"\\nüìÖ Year-by-Year Performance:\")\n",
    "    display(yearly_df.round(2))\n",
    "    \n",
    "    return yearly_df\n",
    "\n",
    "# Analyze Bitcoin trends if available\n",
    "bitcoin_yearly = None\n",
    "if 'Bitcoin' in processed_crypto_data:\n",
    "    bitcoin_yearly = analyze_bitcoin_trends(processed_crypto_data['Bitcoin'])\n",
    "\n",
    "# Plot Bitcoin price history with moving averages\n",
    "if 'Bitcoin' in processed_crypto_data:\n",
    "    btc_df = processed_crypto_data['Bitcoin']\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Main price plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(btc_df.index, btc_df['Close'], label='Bitcoin Price', linewidth=2, color='orange')\n",
    "    \n",
    "    # Add moving averages\n",
    "    if 'MA30' in btc_df.columns:\n",
    "        plt.plot(btc_df.index, btc_df['MA30'], label='30-day MA', alpha=0.7, color='blue')\n",
    "    if 'MA90' in btc_df.columns:\n",
    "        plt.plot(btc_df.index, btc_df['MA90'], label='90-day MA', alpha=0.7, color='green')\n",
    "    if 'MA200' in btc_df.columns:\n",
    "        plt.plot(btc_df.index, btc_df['MA200'], label='200-day MA', alpha=0.7, color='red')\n",
    "    \n",
    "    plt.title('Bitcoin Price History with Moving Averages', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Price (USD)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yscale('log')  # Log scale for better visualization\n",
    "    \n",
    "    # Volume subplot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    if 'Volume' in btc_df.columns:\n",
    "        plt.plot(btc_df.index, btc_df['Volume'], color='purple', alpha=0.7)\n",
    "        plt.title('Bitcoin Trading Volume', fontsize=14, fontweight='bold')\n",
    "        plt.ylabel('Volume', fontsize=12)\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-cryptocurrency comparison\n",
    "def plot_normalized_comparison(crypto_data):\n",
    "    \"\"\"Plot normalized price comparison of all cryptocurrencies\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Find common date range\n",
    "    start_dates = [df.index.min() for df in crypto_data.values()]\n",
    "    end_dates = [df.index.max() for df in crypto_data.values()]\n",
    "    common_start = max(start_dates)\n",
    "    common_end = min(end_dates)\n",
    "    \n",
    "    print(f\"üìä Multi-Cryptocurrency Comparison\")\n",
    "    print(f\"   ‚Ä¢ Common date range: {common_start.date()} to {common_end.date()}\")\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(crypto_data)))\n",
    "    \n",
    "    for i, (name, df) in enumerate(crypto_data.items()):\n",
    "        if 'Close' in df.columns:\n",
    "            # Filter to common date range\n",
    "            filtered_df = df[(df.index >= common_start) & (df.index <= common_end)]\n",
    "            \n",
    "            if len(filtered_df) > 0:\n",
    "                # Normalize to base 100 (starting value = 100)\n",
    "                normalized_prices = (filtered_df['Close'] / filtered_df['Close'].iloc[0]) * 100\n",
    "                \n",
    "                plt.plot(filtered_df.index, normalized_prices, \n",
    "                        label=name, linewidth=2, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    plt.title('Normalized Cryptocurrency Price Comparison (Base = 100)', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Normalized Price', fontsize=12)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate relative performance\n",
    "    performance_summary = []\n",
    "    \n",
    "    for name, df in crypto_data.items():\n",
    "        if 'Close' in df.columns:\n",
    "            filtered_df = df[(df.index >= common_start) & (df.index <= common_end)]\n",
    "            if len(filtered_df) > 1:\n",
    "                start_price = filtered_df['Close'].iloc[0]\n",
    "                end_price = filtered_df['Close'].iloc[-1]\n",
    "                total_return = ((end_price - start_price) / start_price) * 100\n",
    "                \n",
    "                performance_summary.append({\n",
    "                    'Cryptocurrency': name,\n",
    "                    'Start_Price': start_price,\n",
    "                    'End_Price': end_price,\n",
    "                    'Total_Return_Pct': total_return\n",
    "                })\n",
    "    \n",
    "    performance_df = pd.DataFrame(performance_summary)\n",
    "    performance_df = performance_df.sort_values('Total_Return_Pct', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüèÜ Performance Ranking (Common Period):\")\n",
    "    display(performance_df.round(2))\n",
    "    \n",
    "    return performance_df\n",
    "\n",
    "# Generate multi-crypto comparison\n",
    "if len(processed_crypto_data) > 1:\n",
    "    performance_ranking = plot_normalized_comparison(processed_crypto_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market capitalization evolution\n",
    "def analyze_market_cap_evolution(crypto_data):\n",
    "    \"\"\"Analyze market capitalization trends\"\"\"\n",
    "    \n",
    "    print(\"üí∞ Market Capitalization Evolution Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check which cryptocurrencies have market cap data\n",
    "    cryptos_with_mcap = []\n",
    "    for name, df in crypto_data.items():\n",
    "        if 'Market Cap' in df.columns and not df['Market Cap'].isnull().all():\n",
    "            cryptos_with_mcap.append(name)\n",
    "    \n",
    "    print(f\"üìä Cryptocurrencies with Market Cap data: {len(cryptos_with_mcap)}\")\n",
    "    \n",
    "    if cryptos_with_mcap:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(cryptos_with_mcap)))\n",
    "        \n",
    "        for i, name in enumerate(cryptos_with_mcap):\n",
    "            df = crypto_data[name]\n",
    "            mcap_data = df['Market Cap'].dropna()\n",
    "            \n",
    "            if len(mcap_data) > 0:\n",
    "                plt.plot(mcap_data.index, mcap_data.values, \n",
    "                        label=name, linewidth=2, color=colors[i], alpha=0.8)\n",
    "        \n",
    "        plt.title('Market Capitalization Evolution', fontsize=16, fontweight='bold')\n",
    "        plt.ylabel('Market Cap (USD)', fontsize=12)\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.yscale('log')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Current market cap ranking\n",
    "        current_mcaps = []\n",
    "        for name in cryptos_with_mcap:\n",
    "            df = crypto_data[name]\n",
    "            current_mcap = df['Market Cap'].dropna().iloc[-1] if not df['Market Cap'].dropna().empty else 0\n",
    "            current_mcaps.append({\n",
    "                'Cryptocurrency': name,\n",
    "                'Current_Market_Cap': current_mcap\n",
    "            })\n",
    "        \n",
    "        mcap_ranking = pd.DataFrame(current_mcaps)\n",
    "        mcap_ranking = mcap_ranking.sort_values('Current_Market_Cap', ascending=False)\n",
    "        mcap_ranking['Market_Cap_Billions'] = mcap_ranking['Current_Market_Cap'] / 1e9\n",
    "        \n",
    "        print(f\"\\nüìä Current Market Cap Ranking:\")\n",
    "        display(mcap_ranking[['Cryptocurrency', 'Market_Cap_Billions']].round(2))\n",
    "        \n",
    "        return mcap_ranking\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No market cap data available for analysis\")\n",
    "        return None\n",
    "\n",
    "# Analyze market cap evolution\n",
    "mcap_analysis = analyze_market_cap_evolution(processed_crypto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0ca45",
   "metadata": {},
   "source": [
    "## üìã Phase 2-5 Summary\n",
    "\n",
    "Let's summarize what we've accomplished in these phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecc046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive summary of Phases 2-5\n",
    "print(\"üéØ PHASE 2-5 COMPLETION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n‚úÖ PHASE 2: Data Loading & Understanding\")\n",
    "print(f\"   ‚Ä¢ Loaded {len(crypto_data)} cryptocurrencies successfully\")\n",
    "print(f\"   ‚Ä¢ Discovered {len(available_cryptos)} available datasets\")\n",
    "print(f\"   ‚Ä¢ Established data loading framework\")\n",
    "\n",
    "print(f\"\\n‚úÖ PHASE 3: Data Preprocessing & Feature Engineering\")\n",
    "processed_count = len(processed_crypto_data)\n",
    "total_features = sum(len(df.columns) for df in processed_crypto_data.values())\n",
    "print(f\"   ‚Ä¢ Processed {processed_count} cryptocurrency datasets\")\n",
    "print(f\"   ‚Ä¢ Generated {total_features} total features across all cryptocurrencies\")\n",
    "print(f\"   ‚Ä¢ Added derived metrics: returns, volatility, moving averages, technical indicators\")\n",
    "\n",
    "print(f\"\\n‚úÖ PHASE 4: Exploratory Data Analysis\")\n",
    "print(f\"   ‚Ä¢ Generated comprehensive statistics for all cryptocurrencies\")\n",
    "print(f\"   ‚Ä¢ Identified data quality issues and patterns\")\n",
    "print(f\"   ‚Ä¢ Calculated risk and performance metrics\")\n",
    "\n",
    "print(f\"\\n‚úÖ PHASE 5: Historical Trend Analysis\")\n",
    "print(f\"   ‚Ä¢ Analyzed Bitcoin's historical price evolution\")\n",
    "print(f\"   ‚Ä¢ Created normalized multi-cryptocurrency comparisons\")\n",
    "if mcap_analysis is not None:\n",
    "    print(f\"   ‚Ä¢ Examined market capitalization trends\")\n",
    "print(f\"   ‚Ä¢ Generated year-over-year performance analysis\")\n",
    "\n",
    "# Key insights summary\n",
    "print(f\"\\nüí° KEY INSIGHTS DISCOVERED:\")\n",
    "\n",
    "if not comprehensive_stats.empty:\n",
    "    # Performance insights\n",
    "    if 'Total_Return_Pct' in comprehensive_stats.columns:\n",
    "        best_crypto = comprehensive_stats.loc[comprehensive_stats['Total_Return_Pct'].idxmax()]\n",
    "        worst_crypto = comprehensive_stats.loc[comprehensive_stats['Total_Return_Pct'].idxmin()]\n",
    "        print(f\"   ‚Ä¢ Best performer: {best_crypto['Cryptocurrency']} ({best_crypto['Total_Return_Pct']:.1f}% return)\")\n",
    "        print(f\"   ‚Ä¢ Worst performer: {worst_crypto['Cryptocurrency']} ({worst_crypto['Total_Return_Pct']:.1f}% return)\")\n",
    "    \n",
    "    # Risk insights\n",
    "    if 'Annualized_Volatility' in comprehensive_stats.columns:\n",
    "        most_volatile = comprehensive_stats.loc[comprehensive_stats['Annualized_Volatility'].idxmax()]\n",
    "        least_volatile = comprehensive_stats.loc[comprehensive_stats['Annualized_Volatility'].idxmin()]\n",
    "        print(f\"   ‚Ä¢ Most volatile: {most_volatile['Cryptocurrency']} ({most_volatile['Annualized_Volatility']:.1%})\")\n",
    "        print(f\"   ‚Ä¢ Least volatile: {least_volatile['Cryptocurrency']} ({least_volatile['Annualized_Volatility']:.1%})\")\n",
    "\n",
    "# Data quality summary\n",
    "total_missing = sum(df.isnull().sum().sum() for df in processed_crypto_data.values())\n",
    "total_records = sum(len(df) for df in processed_crypto_data.values())\n",
    "overall_completeness = ((total_records * len(processed_crypto_data[list(processed_crypto_data.keys())[0]].columns) - total_missing) / \n",
    "                       (total_records * len(processed_crypto_data[list(processed_crypto_data.keys())[0]].columns))) * 100\n",
    "\n",
    "print(f\"\\nüìä DATA QUALITY METRICS:\")\n",
    "print(f\"   ‚Ä¢ Overall data completeness: {overall_completeness:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Total records processed: {total_records:,}\")\n",
    "print(f\"   ‚Ä¢ Average features per cryptocurrency: {total_features//processed_count}\")\n",
    "\n",
    "print(f\"\\nüöÄ READY FOR NEXT PHASES:\")\n",
    "print(f\"   ‚Ä¢ Phase 6: Bitcoin Dominance Analysis\")\n",
    "print(f\"   ‚Ä¢ Phase 7: Volatility Analysis\")\n",
    "print(f\"   ‚Ä¢ Phase 8: Correlation Analysis\")\n",
    "print(f\"   ‚Ä¢ Phase 9: Seasonal Pattern Analysis\")\n",
    "print(f\"   ‚Ä¢ Phase 10: Predictive Modeling\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"üìã Phases 2-5 completed successfully! üéâ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
